This guide is for building SDPB.  To just run SDPB, it may be easier
to use [Docker](docs/Docker.md) or [Singularity](docs/Singularity.md).
In addition, there are [site specific
notes](docs/site_installs/Readme.md) for different HPC machines and also
for [Apple MacBooks](docs/site_installs/Apple_MacBook.md).

* [Requirements](#requirements)
* [Installation](#installation)
* [Tests](#tests)
* [Getting Help](#getting-help)

# Requirements

SDPB requires

- A modern C++ compiler with C++ 17 support.  SDPB has been tested with
  GCC versions 8 through 12.

- An MPI implementation such as [OpenMPI](https://www.open-mpi.org/) or [MPICH](https://www.mpich.org/)

- [Boost C++ Libraries](http://www.boost.org/) Please be sure that the
  boost library is compiled with the same C++ compiler you are using.

- [The GNU Multiprecision Library](https://gmplib.org/) (6.2.1 or later).  Be sure to
  enable C++ support by configuring with the option `--enable-cxx`.

- [The GNU MPFR Library](https://www.mpfr.org/)  (4.1.0 or later)

- [libxml2](http://www.xmlsoft.org/).  Only the C library is required.

- [RapidJSON](http://rapidjson.org/)

- A BLAS library such as [OpenBLAS](http://www.openblas.net/)

- [Python](https://python.org) (2.7 or later).

- [CMake](https://cmake.org/)

- [libarchive](https://github.com/libarchive/libarchive)

- [FLINT](https://github.com/flintlib/flint)

SDPB has only been tested on Linux (Debian buster and Centos 7).  On
Centos 7, the system compiler (gcc 4.8.5) is too old to support
C++ 17. So you will have to install a newer compiler and Boost. The
system versions of GMP, MPFR, and libxml2 have been tested to work.

In principle, SDPB should be installable on Mac OS X using a package
manager such as [Homebrew](https://brew.sh).

# Installation

1. Download the fork of [Elemental](https://gitlab.com/bootstrapcollaboration/elemental)

        git clone https://gitlab.com/bootstrapcollaboration/elemental.git

2. Make the build directory and cd into it.

        mkdir -p elemental/build
        cd elemental/build

3. Configure Elemental.  This can be rather tricky.  You may have to specify where the Boost, GMP, and BLAS libraries are.  If you are using [modules](http://modules.sourceforge.net/), you may have to load modules.  If these define appropriate environment variables, then the configure should be relatively easy.  For example, on Yale's Grace cluster, commands that work are
   
        module load git CMake GCCcore/6.4.0 OpenMPI/2.1.2-GCC-6.4.0-2.28 Boost/1.66.0-foss-2018a OpenBLAS/0.2.20-GCC-6.4.0-2.28 GMP/6.1.2-GCCcore-6.4.0 MPFR/4.0.1-GCCcore-6.4.0 Python/3.6.4-foss-2018a
        export CXX=mpicxx
        export CC=mpicc
        cmake .. -DCMAKE_INSTALL_PREFIX=$HOME/project/install

    On Harvard's Odyssey3 cluster, the default Boost module does not
    work with the most up-to-date compiler.
    
        module load gcc/9.2.0-fasrc01 cmake/3.16.1-fasrc01 OpenBLAS/0.3.7-fasrc02 openmpi/4.0.2-fasrc01 eigen/3.3.7-fasrc02 libxml2/2.7.8-fasrc02 metis/5.1.0-fasrc01
        module unload boost
        export CXX=mpicxx
        export CC=mpicc
        cmake .. -DCMAKE_INSTALL_PREFIX=$HOME/install

    On a Debian Buster laptop, use sudo or the root account to
    install these packages
    
        apt-get install openmpi-bin libopenmpi-dev libgmp-dev libmpfr-dev libmpfrc++-dev libboost-all-dev g++ cmake libopenblas-dev libxml2-dev git libmetis-dev pkg-config rapidjson-dev
    
    and then configure as a normal user
    
        cmake .. -DCMAKE_CXX_COMPILER=mpicxx -DCMAKE_C_COMPILER=mpicc -DCMAKE_INSTALL_PREFIX=/home/boo/qft/src/elemental/install

4. Build and install Elemental

        make && make install
        cd ../..

5. Install [FLINT](https://github.com/flintlib/flint) library
 
        git clone https://github.com/flintlib/flint.git
        cd flint
        ./bootstrap.sh
        ./configure --disable-static --enable-assert --prefix=$HOME/install
        make
        make check
        make install
        cd ..

   See [FLINT documentation](https://flintlib.org/doc/building.html) for installation instructions.

6. Download SDPB

        git clone https://github.com/davidsd/sdpb
        cd sdpb

    You must use git.  The tarball generated by github will not work.

7. Configure the project using the included version of [waf](https://waf.io). Waf can usually find libraries that are in
   system directories or have corresponding environment variables. You may have to explicitly tell it where other
   libraries are. If you are having problems, running `./waf --help` will give you a list of options.
   
   For example, on Debian buster, a working command is

        ./waf configure --elemental-dir=$HOME/install --flint-dir=$HOME/install

8. Type `./waf` to build the executable in `build/sdpb`. This will create eight executables in the `build/` directory:

    * `sdpb`: Semidefinite program solver
       * `pmp2sdp`: Convert Polynomial Matrix Program (PMP) in JSON, Mathematica or XML format to `sdpb` input.
    * `outer_limits`: Semidefinite program solver using the outer approximation (experimental)
       * `pmp2functions`: Convert PMP in JSON, Mathematica or XML format to `outer_limits` input.
    * `spectrum`: Extract the spectrum given the solution and PMP in JSON/Mathematica/XML format.
    * `approx_objective`: Compute an approximate objective given a solution to a nearby SDP.
    * `unit_tests`: Unit tests.
    * `integration_tests`: End-to-end tests for `sdpb` and other executables. The tests use data from `test/data/` folder.

Running

        ./build/sdpb --help

should give you a usage message. HPC systems may require you to run
all jobs through a batch system. You will need to consult the
documentation for your individual system.

# Tests<a name="tests" />

You can check the installation by running `unit_tests` and `integration_tests` (takes up to several minutes):

        mpirun -n 6 ./build/unit_tests
        ./build/integration_tests

If some integration test case fails, you may check the test logs in `test/out/log/` folder and files generated during
the test run in `test/out/` folder.

By default, `integration_tests` uses `mpirun` command to run `sdpb` and other executables. You can also provide a custom
command for your HPC, e.g.:

        ./build/integration_tests --mpirun="srun --mpi=pmi2" 

For more command-line options,
see [Catch2 documentation](https://github.com/catchorg/Catch2/blob/devel/docs/command-line.md).

You can also run both unit and integration tests via the script

        ./test/run_all_tests.sh

It also supports custom mpirun command, e.g.

        ./test/run_all_tests.sh srun --mpi=pmi2

# Getting Help<a name="getting-help" />
If you are having problems with installation, you can [create an issue on GitHub](https://github.com/davidsd/sdpb/issues/new).
Be sure to include what system you are trying
to install SDPB on, what you typed, and the **FULL** error message
(even if you think it is too long).

If installation was successful but some test case fails, please include also the console output and (in the case of
integration tests) the corresponding logs, e.g. `test/out/log/sdpb/run.stdout.log`
and `test/out/log/sdpb/run.stderr.log`.
